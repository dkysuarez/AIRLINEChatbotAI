import streamlit as st
import ollama

# ConfiguraciÃ³n de la pÃ¡gina
st.set_page_config(page_title="Maharaja - Air India", page_icon="ğŸ›«")
st.title("ğŸ›« Maharaja - Asistente de Air India")
st.markdown("**Â¡Namaste!** Soy Maharaja, tu asistente personal de Air India. "
            "Puedo ayudarte con equipaje, check-in, vuelos y mÃ¡s. âœˆï¸")

# Historial de mensajes
if "messages" not in st.session_state:
    st.session_state.messages = []

# Mostrar mensajes anteriores
for message in st.session_state.messages:
    with st.chat_message(message["role"]):
        st.markdown(message["content"])

# Input del usuario
if prompt := st.chat_input("Â¿En quÃ© puedo ayudarte hoy?"):
    # AÃ±adir mensaje del usuario
    st.session_state.messages.append({"role": "user", "content": prompt})
    with st.chat_message("user"):
        st.markdown(prompt)

    # Generar respuesta
    with st.chat_message("assistant"):
        with st.spinner("Pensando..."):
            # System prompt con personalidad de Air India
            system_message = {
                "role": "system",
                "content": "Eres Maharaja, un asistente amable, profesional y Ãºtil de Air India. "
                           "Responde siempre en espaÃ±ol o inglÃ©s segÃºn el idioma del usuario. "
                           "SÃ© claro, preciso y ofrece mÃ¡s ayuda al final. "
                           "Usa emojis relacionados con viajes cuando sea adecuado. "
                           "Si no estÃ¡s seguro de algo, recomienda visitar www.airindia.com."
            }

            # Historial completo para el modelo
            messages = [system_message] + st.session_state.messages

            # Llamada a Ollama con streaming
            stream = ollama.chat(
                model='phi3:mini',  # Cambia aquÃ­ si usas otro modelo (ej: llama3.2:1b)
                messages=messages,
                stream=True
            )

            # Mostrar respuesta letra por letra
            response = st.write_stream(chunk['message']['content'] for chunk in stream)

    # Guardar respuesta del asistente
    st.session_state.messages.append({"role": "assistant", "content": response})